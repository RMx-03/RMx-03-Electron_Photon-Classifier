{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELECTORN/PHOTON CLASSIFICATION USING ResNet-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJECTIVE: \n",
    "#### Build a Deep Learning Model to Classify between electrons and photons using the provided datasets.\n",
    "    - Preprocess the datasets \n",
    "    - Normalize and prepare the data for model building\n",
    "    - Train a ResNet CNN model\n",
    "    - Evaluation and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electron dataset\n",
    "electron_file = h5py.File(\"SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\", \"r\")  # open the file in read mode \n",
    "# photon dataset\n",
    "photon_file = h5py.File(\"SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\", \"r\")\n",
    "\n",
    "# print dataset keys\n",
    "print(list(electron_file.keys()))\n",
    "print(list(photon_file.keys()))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction of image data and labels\n",
    "\n",
    "with electron_file as f:\n",
    "    X_electron = np.array(f[\"X\"])  # images\n",
    "    y_electron = np.array(f[\"y\"])  # labels\n",
    "\n",
    "with photon_file as f:\n",
    "    X_photon = np.array(f[\"X\"])  \n",
    "    y_photon = np.array(f[\"y\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSPECTING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the datasets\n",
    "print(\"Electron dataset shape:\", X_electron.shape, y_electron.shape)\n",
    "print(\"Photon dataset shape:\", X_photon.shape, y_photon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the  data types\n",
    "print(\"Electron dataset data type:\", X_electron.dtype, y_electron.dtype)\n",
    "print(\"Photon dataset data type:\", X_photon.dtype, y_photon.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Distribution\n",
    "print(\"Electron label distribution:\", np.unique(y_electron, return_counts=True))\n",
    "print(\"Photon label distribution:\", np.unique(y_photon, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "    - Sample size total: 498,000 with a ratio of 1:1 for e:p, so the dataset is balanced in sample size.\n",
    "    - Image Format: 32X32 with 2 channels\n",
    "                - Channel 1: Hit energy (X[:, :, :, 0])\n",
    "                - Channel 2: Hit time (X[:, :, :, 1])\n",
    "    - Labels: \n",
    "        - Electrons: 1\n",
    "        - Photons: 0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLORATORY DATA ANALYSIS (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VISUALIZING SOME SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(data, title, index=0):\n",
    "    energy = data[index, :, :, 0]  # First Channel (energy)\n",
    "    time = data[index, :, :, 1]  # Second Channel (time)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    ax[0].imshow(energy, cmap=\"viridis\")\n",
    "    ax[0].set_title(f\"{title} - Energy\")\n",
    "    ax[1].imshow(time, cmap=\"magma\")\n",
    "    ax[1].set_title(f\"{title} - Time\")\n",
    "    plt.show()\n",
    "\n",
    "plot_sample(X_electron, \"Electron Sample\", index=0)\n",
    "plot_sample(X_photon, \"Photon Sample\", index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- Helps us in visualizing how the electrons and photons differ in energy deposition through the detector.\n",
    "- These energy deposition patterns can help in classificaiton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LABEL DISTRIBUTION: VISUALIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate([y_electron, y_photon])\n",
    "sns.histplot(labels, bins=2)\n",
    "plt.xticks([0, 1], [\"Photon (0)\", \"Electron (1)\"])\n",
    "plt.title(\"Label Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMBINE AND NORMALIZE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Datasets\n",
    "X = np.concatenate([X_electron, X_photon], axis=0)\n",
    "y = np.concatenate([np.ones_like(y_electron), np.zeros_like(y_photon)], axis=0)\n",
    "\n",
    "\n",
    "# Normalizing energy and time channels\n",
    "X[:, :, :, 0] /= np.max(X[:, :, :, 0])  # Energy\n",
    "X[:, :, :, 1] /= np.max(X[:, :, :, 1])  # Time\n",
    "\n",
    "\n",
    "print(\"Dataset Shape:\", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL BUILDING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage the problem of vanishing gradients \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)  # Batch Normalization layer\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Identify Shortcut Connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = torch.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity  # skip connection \n",
    "        return torch.relu(out)\n",
    "    \n",
    "class ResNetModified(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ResNetModified, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self.__make_layer(64, 128, stride=1)\n",
    "        self.layer2 = self.__make_layer(128,256, stride=2)\n",
    "        self.layer3 = self.__make_layer(256, 512, stride=2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        return nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels, stride),\n",
    "            ResidualBlock(out_channels, out_channels, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))  # initial convolutional layer\n",
    "        x = self.layer1(x)  # residual block 1\n",
    "        x = self.layer2(x)  # residual block 2\n",
    "        x = self.layer3(x)  # residual block 3\n",
    "        x = self.avg_pool(x)  # Global average pooling\n",
    "        x = torch.flatten(x, 1)  # flatten for FC layer\n",
    "        return self.fc(x)  # Fully connected layer\n",
    "    \n",
    "\n",
    "# Instantiate the model\n",
    "model = ResNetModified()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOSS AND OPTIMIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAINING PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import torch.utils.data as data\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "train_dataset = data.TensorDataset(torch.tensor(X_train, dtype=torch.float32).permute(0, 3, 1, 2), torch.tensor(y_train, dtype=torch.long))\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 5\n",
    "best_accuracy = 0.0\n",
    "best_model_path = \"best_model.pth\"\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criteria(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds) * 100\n",
    "    precision = precision_score(all_labels, all_preds, average=\"weighted\") * 100\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"new best model saved with accuracy: {best_accuracy:.2f}%\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "          f\"Accuracy: {accuracy:.2f}%, Precision: {precision:.2f}%, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "print(f\"training completed. Best accuracy: {best_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
